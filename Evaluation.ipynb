{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4b4b9aa-3e52-4d44-8a90-59dfb4a9dfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[28183    22]\n",
      " [   27  9432]]\n",
      "\n",
      "Klassifikationsbericht:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       1.00      1.00      1.00     28205\n",
      "        hoch       1.00      1.00      1.00      9459\n",
      "\n",
      "    accuracy                           1.00     37664\n",
      "   macro avg       1.00      1.00      1.00     37664\n",
      "weighted avg       1.00      1.00      1.00     37664\n",
      "\n",
      "Spezifität: 0.9992\n"
     ]
    }
   ],
   "source": [
    "# 1. Bibliotheken importieren\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 2. CSV-Datei laden\n",
    "df = pd.read_csv(\"C:/Users/Nael Ackle/OneDrive - BBBaden/Dokumente/IAP/Modul 259/main.csv\")\n",
    "\n",
    "# 3. Zielklassifikation erstellen: \"Close\" in Klassen unterteilen (hoch / normal)\n",
    "grenzwert = df[\"Close\"].quantile(0.75)  # oberes Quartil\n",
    "df[\"Close_Klasse\"] = (df[\"Close\"] >= grenzwert).astype(int)  # 1 = hoch, 0 = normal\n",
    "\n",
    "# 4. Features und Ziel festlegen\n",
    "X = df[[\"Open\", \"High\", \"Low\", \"Volume\"]]\n",
    "y = df[\"Close_Klasse\"]\n",
    "\n",
    "# 5. Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Logistisches Regressionsmodell erstellen und trainieren\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 7. Vorhersagen erzeugen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 8. Confusion Matrix ausgeben\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# 9. Klassifikationsbericht ausgeben\n",
    "print(\"\\nKlassifikationsbericht:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"normal\", \"hoch\"]))\n",
    "\n",
    "# 10. Spezifität manuell berechnen\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "spezifitaet = tn / (tn + fp)\n",
    "print(f\"Spezifität: {spezifitaet:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e447af99-7512-4e3f-9d2b-f558092534b4",
   "metadata": {},
   "source": [
    "### Bewertung und Fazit\n",
    "\n",
    "Das Modell zeigt aussergewöhnlich gute Ergebnisse mit einer Genauigkeit von nahezu 100 %. Sowohl Sensitivität als auch Spezifität sind extrem hoch.\n",
    "Die Confusion Matrix bestätigt, dass fast alle Vorhersagen korrekt getroffen wurden. \n",
    "Solch ein Ergebnis deutet darauf hin, dass die Klassen sehr gut voneinander getrennt werden können – möglicherweise aufgrund einer starken Korrelation zwischen den Eingabedaten und der Zielvariable.\n",
    "Für eine Klassifikation von „hohen“ vs. „normalen“ Schlusskursen ist dieses Modell sehr gut geeignet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb39d07-6b36-4b42-89c7-b08db02a7bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
